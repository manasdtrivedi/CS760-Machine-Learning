{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a458bd6c-1098-4124-b986-20f95f18e583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "cd1a179d-182a-4903-ae13-2217b8bf0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(candidate_splits):\n",
    "    \n",
    "    best_split = max(candidate_splits, key = lambda x: x[3])\n",
    "    return best_split[0], best_split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "7ba0b98e-c125-4531-94eb-eae658c23a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logbase2(n):\n",
    "    if n != 0:\n",
    "        return math.log(n, 2)\n",
    "    else:\n",
    "        return -sys.float_info.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8a3c360e-11f8-4fa0-8389-c30a9ee480ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_entropy(a, b):\n",
    "    \n",
    "    total = a + b\n",
    "    \n",
    "    prob_a = a/total\n",
    "    prob_b = b/total\n",
    "    \n",
    "    entropy = - (prob_a * logbase2(prob_a)) - (prob_b * logbase2(prob_b))\n",
    "    \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "6e654190-d6ee-4294-a7f0-02c07580104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_info_gain_and_split_info(total_number_of_zeros, total_number_of_ones, number_of_zeros_left, number_of_ones_left, number_of_zeros_right, number_of_ones_right):\n",
    "\n",
    "    entropy_y = calculate_entropy(total_number_of_zeros, total_number_of_ones)\n",
    "    entropy_y_left = calculate_entropy(number_of_zeros_left, number_of_ones_left)\n",
    "    entropy_y_right = calculate_entropy(number_of_zeros_right, number_of_ones_right)\n",
    "\n",
    "    total_zeros_and_ones_left = number_of_zeros_left + number_of_ones_left\n",
    "    total_zeros_and_ones_right = number_of_zeros_right + number_of_ones_right\n",
    "\n",
    "    weight_left = total_zeros_and_ones_left / (total_number_of_zeros + total_number_of_ones)\n",
    "    weight_right = total_zeros_and_ones_right / (total_number_of_zeros + total_number_of_ones)\n",
    "\n",
    "    info_gain = entropy_y - (weight_left * entropy_y_left) - (weight_right * entropy_y_right)\n",
    "    split_info = calculate_entropy(total_zeros_and_ones_left, total_zeros_and_ones_right)\n",
    "\n",
    "    return info_gain, split_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "26e65bb1-a04c-458e-a2d8-c0f657973360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_candidate_splits(df):\n",
    "    # candidate splits is a nested list containing [1, 0.04] i.e. 1 (for x1) and 0.04 for xj's value\n",
    "    candidate_splits = []\n",
    "    df_x1 = df.sort_values('x1')\n",
    "    df_x1 = df_x1.reset_index()\n",
    "    df_x2 = df.sort_values('x2')\n",
    "    df_x2 = df_x2.reset_index()\n",
    "\n",
    "    # total_number_of_zeros = df['y'].value_counts()[0]\n",
    "    # total_number_of_ones = df['y'].value_counts()[1]\n",
    "    total_number_of_zeros = np.sum(df['y'] == 0)\n",
    "    total_number_of_ones = np.sum(df['y'] == 1)\n",
    "    \n",
    "    for i in range(1, len(df)):\n",
    "        \n",
    "        if df_x1['y'][i] != df_x1['y'][i - 1]:\n",
    "            # y has changed\n",
    "            number_of_zeros_left = np.sum(df_x1['y'].iloc[:i] == 0)\n",
    "            number_of_ones_left = np.sum(df_x1['y'].iloc[:i] == 1)\n",
    "            number_of_zeros_right = np.sum(df_x1['y'].iloc[i:] == 0)\n",
    "            number_of_ones_right = np.sum(df_x1['y'].iloc[i:] == 1)\n",
    "            # candidate_splits.append([1, df_x1['x1'][i], total_number_of_zeros, total_number_of_ones, number_of_zeros_left, number_of_ones_left, number_of_zeros_right, number_of_ones_right])\n",
    "            info_gain, split_info = calculate_info_gain_and_split_info(total_number_of_zeros, total_number_of_ones, number_of_zeros_left, number_of_ones_left, number_of_zeros_right, number_of_ones_right)\n",
    "            if split_info != 0.0:\n",
    "                gain_ratio = info_gain / split_info\n",
    "                candidate_splits.append([1, df_x1['x1'][i], info_gain, gain_ratio])\n",
    "            \n",
    "        if df_x2['y'][i] != df_x2['y'][i - 1]:\n",
    "            # y has changed\n",
    "            number_of_zeros_left = np.sum(df_x2['y'].iloc[:i] == 0)\n",
    "            number_of_ones_left = np.sum(df_x2['y'].iloc[:i] == 1)\n",
    "            number_of_zeros_right = np.sum(df_x2['y'].iloc[i:] == 0)\n",
    "            number_of_ones_right = np.sum(df_x2['y'].iloc[i:] == 1)\n",
    "            # candidate_splits.append([2, df_x2['x2'][i], total_number_of_zeros, total_number_of_ones, number_of_zeros_left, number_of_ones_left, number_of_zeros_right, number_of_ones_right])\n",
    "            info_gain, split_info = calculate_info_gain_and_split_info(total_number_of_zeros, total_number_of_ones, number_of_zeros_left, number_of_ones_left, number_of_zeros_right, number_of_ones_right)\n",
    "            if split_info != 0.0:\n",
    "                gain_ratio = info_gain / split_info\n",
    "                candidate_splits.append([2, df_x2['x2'][i], info_gain, gain_ratio])\n",
    "\n",
    "    # We can have empty candidate splits if the df has 0 or 1 rows, or if all rows in df have same y,\n",
    "    # or if none of the splits have non-0 split_info\n",
    "    return candidate_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d08180d6-2afa-4f89-a751-7d97b958babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopping_criteria_satisfied(len_df, set_of_candidate_splits):\n",
    "    # node is empty, or\n",
    "    # all splits have zero gain ratio\n",
    "    if len_df == 0:\n",
    "        return True\n",
    "        \n",
    "    all_splits_have_zero_gain_ratio = True\n",
    "    for candidate_split in set_of_candidate_splits:\n",
    "        if len(candidate_split) >= 4 and candidate_split[3] != 0.0:\n",
    "            all_splits_have_zero_gain_ratio = False\n",
    "            break\n",
    "    if all_splits_have_zero_gain_ratio:\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "1471fc87-e1fe-4c65-b6ff-bba927f1861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    # double check\n",
    "    def __init__(self, feature_number, value, left_child, right_child):\n",
    "        self.feature_number = feature_number\n",
    "        self.value = value\n",
    "        self.left_child = left_child\n",
    "        self.right_child = right_child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "eee25b38-62b9-4c4a-8abf-900842f91094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_subsets(df, feature_number, feature_value):\n",
    "    if feature_number == 0:\n",
    "        df_sorted_on_x1 = df.sort_values('x1')\n",
    "        df_sorted_on_x1 = df_sorted_on_x1.reset_index()\n",
    "        \n",
    "        index_of_x1 = -1\n",
    "        \n",
    "        for i in range(0, len(df)):\n",
    "            if df_sorted_on_x1['x1'][i] == feature_value:\n",
    "                index_of_x1 = i\n",
    "                break\n",
    "            \n",
    "        left_df_subset = df_sorted_on_x1.iloc[index_of_x1:].copy().reset_index()\n",
    "        right_df_subset = df_sorted_on_x1.iloc[:index_of_x1].copy().reset_index()\n",
    "        \n",
    "        return left_df_subset, right_df_subset\n",
    "    else:\n",
    "        df_sorted_on_x2 = df.sort_values('x2')\n",
    "        df_sorted_on_x2 = df_sorted_on_x2.reset_index()\n",
    "        \n",
    "        index_of_x2 = -1\n",
    "\n",
    "        for i in range(0, len(df)):\n",
    "            if df_sorted_on_x2['x2'][i] == feature_value:\n",
    "                index_of_x2 = i\n",
    "                break\n",
    "\n",
    "        left_df_subset = df_sorted_on_x2.iloc[index_of_x2:].copy().reset_index()\n",
    "        right_df_subset = df_sorted_on_x2.iloc[:index_of_x2].copy().reset_index()\n",
    "        \n",
    "        return left_df_subset, right_df_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "23dfe11d-49b2-43da-ae73-15eb2a750855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_class_label(df):\n",
    "    if len(df) == 0:\n",
    "        return 1\n",
    "    number_of_zeros = np.sum(df['y'] == 0)\n",
    "    number_of_ones = np.sum(df['y'] == 1)\n",
    "    if number_of_zeros > number_of_ones:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "466dc658-8137-4e54-8ba7-0b8b88272e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_subtree(df):\n",
    "    \n",
    "    candidate_splits = determine_candidate_splits(df)\n",
    "    \n",
    "    if stopping_criteria_satisfied(len(df), candidate_splits):\n",
    "        \n",
    "        # Make leaf node, and assign a class label to it\n",
    "        class_label = determine_class_label(df)\n",
    "        leaf_node = Node(None, class_label, None, None)\n",
    "        \n",
    "        return leaf_node\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Make internal node, assign split condition and children\n",
    "        feature_number, feature_value = find_best_split(candidate_splits)\n",
    "        \n",
    "        left_df_subset, right_df_subset = get_df_subsets(df, feature_number, feature_value)\n",
    "\n",
    "        print(\"left_df_subset: \", left_df_subset)\n",
    "        print(\"right_df_subset: \", right_df_subset)\n",
    "        \n",
    "        left_child = make_subtree(left_df_subset)\n",
    "        right_child = make_subtree(right_df_subset)\n",
    "        \n",
    "        internal_node = Node(feature_number, feature_value, left_child, right_child)\n",
    "        \n",
    "        return internal_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "370e7565-cd60-4cd7-9c30-2770f9ff153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_preorder_traversal(node, height):\n",
    "    if node:\n",
    "        if node.feature_number != None:\n",
    "            print(\"    \" * height + \"x\" + str(node.feature_number) + \" >= \" + str(node.value))\n",
    "        else:\n",
    "            print(\"    \" * height + \"y = \" + str(node.value))\n",
    "        \n",
    "        print_preorder_traversal(node.left_child, height + 1)\n",
    "        print_preorder_traversal(node.right_child, height + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "a14c6fde-ceeb-42c8-ab8a-6d77c5350e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_df_subset:     level_0  index    x1    x2  y\n",
      "0        2      2  0.02  0.03  1\n",
      "1        3      3  0.01  0.04  1\n",
      "right_df_subset:     level_0  index    x1    x2  y\n",
      "0        0      0  0.04  0.01  0\n",
      "1        1      1  0.03  0.02  0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert level_0, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bs/bjjtd9357ndb2xjb66592czm0000gq/T/ipykernel_19910/4248539227.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mroot_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bs/bjjtd9357ndb2xjb66592czm0000gq/T/ipykernel_19910/3834297321.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"left_df_subset: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"right_df_subset: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mleft_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mright_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_df_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0minternal_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_child\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_child\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bs/bjjtd9357ndb2xjb66592czm0000gq/T/ipykernel_19910/3834297321.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmake_subtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcandidate_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_candidate_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstopping_criteria_satisfied\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bs/bjjtd9357ndb2xjb66592czm0000gq/T/ipykernel_19910/2287188590.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_candidate_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# candidate splits is a nested list containing [1, 0.04] i.e. 1 (for x1) and 0.04 for xj's value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcandidate_splits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdf_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdf_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mdf_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mdf_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_x2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6219\u001b[0m                     level_values = algorithms.take(\n\u001b[1;32m   6220\u001b[0m                         \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_na_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6221\u001b[0m                     )\n\u001b[1;32m   6222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6223\u001b[0;31m                 new_obj.insert(\n\u001b[0m\u001b[1;32m   6224\u001b[0m                     \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6225\u001b[0m                     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6226\u001b[0m                     \u001b[0mlevel_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   4930\u001b[0m                 \u001b[0;34m\"'self.flags.allows_duplicate_labels' is False.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4931\u001b[0m             )\n\u001b[1;32m   4932\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4933\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4934\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {column}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4935\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4936\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc must be int\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4937\u001b[0m         \u001b[0;31m# convert non stdlib ints to satisfy typing checks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert level_0, already exists"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('test.txt', delim_whitespace=True, header = None)\n",
    "df.columns = ['x1', 'x2', 'y']\n",
    "\n",
    "root_node = make_subtree(df)\n",
    "\n",
    "print_preorder_traversal(root_node, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157687a-123c-4f37-b0b0-b24079b8bb5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
